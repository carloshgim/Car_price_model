{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción del valor de mercado de autos usados: Construcción de un modelo utilizando datos históricos de automóviles para una función de la aplicación que puede determinar el valor de mercado del automóvil de un usuario por *Carlos Horta* (carlosgim@gmail.com)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción: Predicción del valor de mercado de autos usados\n",
    "\n",
    "El servicio de venta de autos usados Rusty Bargain está desarrollando una aplicación para atraer nuevos clientes. Esta aplicación permitirá a los usuarios obtener rápidamente el valor de mercado de su automóvil. Para lograr esto, se requiere crear un modelo que pueda determinar el valor de mercado de los autos.\n",
    "\n",
    "A Rusty Bargain le interesan los siguientes aspectos del modelo:\n",
    "\n",
    "- **Calidad de la predicción:** El modelo debe ser capaz de realizar predicciones precisas y confiables del valor de mercado de los autos usados. Esto es crucial para brindar a los clientes información precisa y ayudarles a tomar decisiones informadas.\n",
    "\n",
    "- **Velocidad de la predicción:** La aplicación busca proporcionar una respuesta rápida a los usuarios. Por lo tanto, es importante que el modelo sea eficiente en términos de tiempo de respuesta al realizar predicciones.\n",
    "\n",
    "- **Tiempo requerido para el entrenamiento:** Además de la velocidad de predicción, Rusty Bargain también considera importante el tiempo necesario para entrenar el modelo. Un tiempo de entrenamiento más corto permitirá a la empresa iterar y actualizar el modelo con mayor agilidad.\n",
    "\n",
    "Para cumplir con estos requisitos, se explorarán diferentes técnicas y algoritmos de Machine Learning que sean capaces de ofrecer una buena calidad de predicción, una velocidad de predicción rápida y un tiempo de entrenamiento eficiente. Se evaluarán y compararán varios modelos para seleccionar la opción que mejor se adapte a las necesidades de Rusty Bargain.\n",
    "\n",
    "El objetivo final es desarrollar un modelo que pueda proporcionar a los usuarios estimaciones precisas y rápidas del valor de mercado de sus autos usados, mejorando así la experiencia del cliente y promoviendo la eficiencia en el proceso de venta de autos usados de Rusty Bargain.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialización "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es necesario cargar las diferentes librerías que se van a utilizar en el desarrollo del proyecto.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial import distance\n",
    "from numpy.random import RandomState\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y definir la semilla aleatoria para que los resultados sean reproducibles.\n",
    "\n",
    "rs = RandomState(seed=1984)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan los datos de los ficheros csv en los dataframes correspondientes.\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('car_data.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/car_data.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se observan los datos del dataframe.\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el DataFrame analizado, se observa que contiene un total de 354,369 registros y 16 columnas. Sin embargo, también se identificó la presencia de datos faltantes en algunas columnas específicas. Las columnas con datos faltantes son las siguientes: VehicleType, Gearbox, Model, FuelType, NotRepaired y NumberOfPictures.\n",
    "\n",
    "Para mejorar la calidad y el estilo del DataFrame, se proponen las siguientes acciones inmediatas:\n",
    "\n",
    "1. **Cambiar los nombres de las columnas a minúsculas**: Se sugiere convertir los nombres de las columnas a minúsculas para mantener la consistencia y facilitar la manipulación de los datos.\n",
    "\n",
    "2. **Reescribir los títulos de acuerdo con las sugerencias de estilo**: Se recomienda revisar y ajustar los títulos de las columnas siguiendo las convenciones de estilo recomendadas, como utilizar letras minúsculas, separadores de palabras (por ejemplo, guiones bajos o camel case) y evitar espacios en blanco o caracteres especiales.\n",
    "\n",
    "Estas acciones inmediatas ayudarán a mejorar la legibilidad, coherencia y uniformidad del DataFrame, facilitando su posterior análisis y manipulación de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'DateCrawled': 'date_crawled', 'Price': 'price', 'VehicleType': 'vehicle_type', 'RegistrationYear': 'registration_year', 'Gearbox': 'gearbox', 'Power': 'power', 'Model': 'model', 'Mileage': 'mileage', 'RegistrationMonth': 'registration_month', 'FuelType': 'fuel_type', 'Brand': 'brand', 'NotRepaired': 'not_repaired', 'DateCreated': 'date_created', 'NumberOfPictures': 'number_of_pictures', 'PostalCode': 'postal_code', 'LastSeen': 'last_seen'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columnas numéricas del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es necesario observar los valores numéricos de las columnas del dataset.\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna 'number of pictures'\n",
    "Como se observa en el análisis, la columna 'number of pictures' contiene únicamente valores de cero en todas las filas. Debido a que esta columna no aporta información relevante para el análisis y no presenta variabilidad, se puede eliminar sin afectar los resultados del proyecto en el siguiente apartado.\n",
    "\n",
    "### Valores no válidos en columnas numéricas\n",
    "Al analizar las columnas restantes con valores numéricos, se identificaron algunos valores que no tienen sentido y que podrían considerarse como datos erróneos. A continuación, se describen los problemas encontrados en cada columna:\n",
    "\n",
    "- **Año de registro**: Se encontraron valores atípicos como 1000 y 9999, que no corresponden a años válidos para el registro de vehículos. Estos datos podrían ser considerados como errores o datos faltantes.\n",
    "\n",
    "- **Potencia en CV**: Se identificaron valores extremos e incoherentes, como cero o cifras muy altas (por ejemplo, 20,000 CV), que no son posibles para la potencia de un vehículo. Estos valores también podrían ser considerados como errores o datos faltantes.\n",
    "\n",
    "- **Mes de registro**: Se observaron filas con un valor de cero en el mes de registro, lo cual no es válido ya que el mes debe estar en el rango de 1 a 12. Estos datos podrían considerarse como errores o datos faltantes.\n",
    "\n",
    "- **Millaje**: Se encontró que la mediana y los cuartiles tercero y cuarto están situados en el valor de 150,000 millas. Esto puede indicar que hay una alta concentración de datos en este valor, lo cual podría afectar la variabilidad de los datos y la capacidad del modelo para capturar diferencias significativas en el millaje de los vehículos.\n",
    "\n",
    "En el siguiente apartado del proyecto se abordarán estas irregularidades y se tomarán las medidas adecuadas, como la limpieza de datos, para garantizar la calidad y la coherencia de los datos utilizados en el análisis.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna 'registration_year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly.subplots as sp\n",
    "\n",
    "# Filtramos los datos de la columna \"registration_year\"\n",
    "df_filtered = df[(df['registration_year'] >= 1900) & (df['registration_year'] <= 2023)]\n",
    "\n",
    "# Creamos el histograma y el boxplot\n",
    "histogram = go.Histogram(x=df_filtered['registration_year'], nbinsx=50, name='Histograma')\n",
    "boxplot = go.Box(x=df_filtered['registration_year'], name='Boxplot')\n",
    "\n",
    "# Creamos un subplot con las dos figuras\n",
    "fig = sp.make_subplots(rows=1, cols=2, subplot_titles=(\"Histograma\", \"Boxplot\"))\n",
    "fig.add_trace(histogram, row=1, col=1)\n",
    "fig.add_trace(boxplot, row=1, col=2)\n",
    "\n",
    "# Ajustamos el layout y mostramos la figura\n",
    "fig.update_layout(title='Análisis de la columna \"registration_year\"', showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se analizó la columna 'registration_year', que consta de 354,369 filas. Sin embargo, se identificó que presenta valores extremos que no son posibles, con un valor mínimo de 1,000 y un valor máximo de 9,999. Estos valores están claramente fuera del rango válido para el año de registro de un vehículo.\n",
    "\n",
    "Para abordar este problema, se realizó un gráfico que delimitó los años entre 1900 y 2023, con el fin de visualizar mejor la distribución de los datos. Sin embargo, incluso con esta delimitación, aún se observan datos extremos en el extremo izquierdo del gráfico.\n",
    "\n",
    "**Decisión sobre la columna 'registration_year':** Para garantizar la integridad y la coherencia de los datos, se ha decidido eliminar los registros que se encuentren fuera del rango entre 1989 y 2019. Este rango se considera más realista y acorde con los años de registro de los vehículos en el contexto del proyecto.\n",
    "\n",
    "Al realizar esta limpieza de datos, se asegurará que los valores en la columna 'registration_year' sean más coherentes y representativos de la realidad. Esta decisión contribuirá a mejorar la calidad de los datos y evitará la inclusión de valores extremos que puedan afectar el análisis y la precisión del modelo.\n",
    "\n",
    "En el siguiente apartado del proyecto se aplicará esta decisión y se procederá a la limpieza de la columna 'registration_year' según el rango especificado.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna 'power'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el histograma\n",
    "hist = go.Histogram(x=df['power'], name='Potencia')\n",
    "\n",
    "# Crear el boxplot\n",
    "box = go.Box(y=df['power'], name='Potencia')\n",
    "\n",
    "# Crear el subplot\n",
    "fig = sp.make_subplots(rows=1, cols=2, subplot_titles=('Histograma', 'Boxplot'))\n",
    "fig.add_trace(hist, row=1, col=1)\n",
    "fig.add_trace(box, row=1, col=2)\n",
    "\n",
    "# Establecer el layout\n",
    "fig.update_layout(width=900, height=400, title='Análisis de la columna \"power\"')\n",
    "\n",
    "# Mostrar la figura\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La potencia en CV (caballos de vapor) es una medida utilizada para determinar la potencia del motor de un vehículo. En general, los valores de potencia en CV se encuentran dentro de un rango específico según el tipo y tamaño del vehículo. Por ejemplo, los carros urbanos suelen tener motores de al menos 60 CV, mientras que los carros grandes de alto rendimiento pueden llegar a tener potencias superiores a los 1,000 CV.\n",
    "\n",
    "Al analizar la columna 'power' en el gráfico anterior, se observa una distribución de datos que alcanza un máximo de 20,000 CV. Sin embargo, esta cifra es extremadamente alta y poco realista en el contexto de los vehículos utilizados en el proyecto.\n",
    "\n",
    "**Decisión sobre la columna 'power':** Con el objetivo de mantener la coherencia y evitar valores extremos que puedan afectar el análisis y la precisión del modelo, se ha decidido eliminar los datos de aquellas filas cuyo valor en la columna 'power' supere los 2,000 caballos de vapor. Esta decisión se basa en consideraciones realistas y en el rango de potencia habitual de los vehículos utilizados en el mercado.\n",
    "\n",
    "Al aplicar esta limpieza de datos, se garantizará que los valores en la columna 'power' sean más consistentes y representativos de los motores de los vehículos. Esto contribuirá a mejorar la calidad de los datos y evitará la inclusión de valores extremos que puedan distorsionar el análisis y los resultados del modelo.\n",
    "\n",
    "En el siguiente apartado del proyecto se llevará a cabo esta acción y se procederá a la limpieza de la columna 'power' eliminando las filas con potencias superiores a los 2,000 caballos de vapor.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna 'mileage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el histograma\n",
    "hist = go.Histogram(x=df['mileage'], name='Kilometraje')\n",
    "\n",
    "# Crear el boxplot\n",
    "box = go.Box(y=df['mileage'], name='Kilometraje')\n",
    "\n",
    "# Crear el subplot\n",
    "fig = sp.make_subplots(rows=1, cols=2, subplot_titles=('Histograma', 'Boxplot'))\n",
    "fig.add_trace(hist, row=1, col=1)\n",
    "fig.add_trace(box, row=1, col=2)\n",
    "\n",
    "# Establecer el layout\n",
    "fig.update_layout(width=900, height=400, title='Análisis de la columna \"mileage\"')\n",
    "\n",
    "# Mostrar la figura\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al analizar la columna 'mileage', se observa una tendencia particular en los datos. Un alto porcentaje de los vehículos tiene un kilometraje registrado de 150,000 kilómetros, lo cual puede resultar sospechoso. Es posible que esto se deba a que, al obtener los datos de esta columna, se registraron valores aproximados en números redondos en lugar de valores exactos.\n",
    "\n",
    "**Decisión sobre la columna 'mileage':** Después de considerar esta observación, se ha decidido mantener los datos tal como se encuentran en el dataset de este proyecto. Aunque existe una aparente estandarización en los valores de kilometraje, se asumirá que estos datos reflejan la información proporcionada y registrada en el sitio Rusty Bargain.\n",
    "\n",
    "No se realizará ninguna modificación ni limpieza adicional en la columna 'mileage' para evitar la introducción de sesgos o pérdida de información en el análisis y en el modelo de predicción del valor de mercado de los vehículos.\n",
    "\n",
    "En el siguiente apartado del proyecto se trabajará con la columna 'mileage' sin realizar modificaciones en sus datos.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna 'registration_month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una columna booleana que indica si el valor de registration_month es cero\n",
    "df[\"is_zero\"] = (df[\"registration_month\"] == 0)\n",
    "\n",
    "# Crea el gráfico, utilizando la columna \"is_zero\" para marcar las filas con valor cero\n",
    "fig = px.histogram(df, x=\"registration_month\", nbins=24, color=\"is_zero\")\n",
    "\n",
    "# Muestra el gráfico\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al analizar la columna 'registration_month', se observa la presencia de 37,532 filas con el valor cero en esta columna. El valor cero no es válido para representar un mes de registro, ya que los meses van del 1 al 12.\n",
    "\n",
    "**Decisión sobre la columna 'registration_month':** Para mantener la coherencia y consistencia de los datos, se ha decidido eliminar las filas que contengan el valor cero en la columna 'registration_month'. Estas filas no aportan información válida y podrían afectar el análisis y los resultados del modelo.\n",
    "\n",
    "Al eliminar estas filas, se asegurará que los valores en la columna 'registration_month' sean coherentes y se correspondan con meses válidos, lo que contribuirá a mejorar la calidad de los datos utilizados en el proyecto.\n",
    "\n",
    "En el siguiente apartado del proyecto se aplicará esta decisión y se procederá a la eliminación de las filas que contengan el valor cero en la columna 'registration_month'."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En resumen sobres las columnas numéricas:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen sobre las columnas numéricas\n",
    "\n",
    "Después de analizar las columnas numéricas, se tomaron las siguientes decisiones para cada una de ellas:\n",
    "\n",
    "- **Columna 'number_of_pictures':** Se eliminó la columna en su totalidad, ya que todas las filas contenían únicamente ceros, lo que la hacía irrelevante para el análisis.\n",
    "\n",
    "- **Columna 'registration_year':** Se eliminaron los datos anteriores a 1989 y posteriores a 2019, ya que se consideraban valores atípicos o incorrectos para el año de registro de un vehículo.\n",
    "\n",
    "- **Columna 'power':** Se eliminaron las filas que contenían valores de potencia superiores a 2,000 caballos de vapor, ya que se consideraban extremadamente altos y poco realistas.\n",
    "\n",
    "- **Columna 'mileage':** Los datos se dejaron tal como estaban en el dataset, ya que no se identificaron problemas significativos o datos incorrectos en esta columna.\n",
    "\n",
    "- **Columna 'postal_code':** La columna se eliminó, ya que no era relevante para el objetivo del proyecto.\n",
    "\n",
    "- **Columna 'registration_month':** Se eliminaron las filas que contenían el valor cero en esta columna, ya que no correspondían a un mes válido de registro.\n",
    "\n",
    "- **Columnas 'date_crawled', 'date_created' y 'last_seen':** Estas columnas se eliminaron, ya que contenían información no relevante para el objetivo del proyecto.\n",
    "\n",
    "Estas acciones ya se han realizado y se ha llevado a cabo la modificación correspondiente en el dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajo de eliminación de filas y/o columnas numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de iniciar la eliminación de valores y columnas numéricas, es necesario realizar una copia del dataframe original.\n",
    "\n",
    "df_copia = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se procede a realizar la eliminación de los valores y columnas numéricas que se describió en el apartado anterior.\n",
    "\n",
    "# Eliminar la columna 'number_of_pictures', 'postal_code', 'date_crawled', 'date_created', 'last_seen'\n",
    "\n",
    "df = df.drop(['number_of_pictures', 'postal_code', 'date_crawled', 'date_created', 'last_seen'], axis=1)\n",
    "\n",
    "# De la columna 'registration_year' se conservan los valores que se encuentren entre los años 1989 y 2019.\n",
    "df = df.loc[(df['registration_year'] >= 1988) & (df['registration_year'] <= 2020)]\n",
    "\n",
    "# De la columna 'power' se eliminarán los valores que se encuentren a partir de 2000 de caballos de vapor.\n",
    "df = df.loc[df['power'] < 2000]\n",
    "\n",
    "# De la columna 'registration_month' se eliminarán los valores que tengan valor cero.   \n",
    "df = df.loc[df['registration_month'] != 0]\n",
    "\n",
    "# Hasta este momento los datos del dataframe se encuentran en el siguiente estado.\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa, los datos de iniciales del dataset era de 354,369 por columna y ahora es de 311,147. En el siguiente apartado se revisarán cada una de las columnas categóricas. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columnas categóricas del dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisarán las columnas categóricas del dataset del proyecto, que incluyen información sobre el tipo de vehículo, el tipo de caja de cambios, el modelo del automóvil, el tipo de combustible, la marca del vehículo y si ha sido reparado o no.\n",
    "\n",
    "Se realizará un análisis de cada una de estas columnas para identificar patrones, valores únicos y posibles acciones a tomar en cada caso."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna \"vehicle_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['vehicle_type'].value_counts())\n",
    "print('---------------------------------')\n",
    "print(df['vehicle_type'].isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de analizar la columna 'vehicle_type', se encontraron 22,267 valores faltantes. Una opción adecuada para incluir estos datos ausentes es utilizar la categoría 'other' (otros), ya que proporciona una clasificación general para los vehículos que no se pueden identificar correctamente.\n",
    "\n",
    "**Decisión sobre la columna 'vehicle_type':** Se ha decidido asignar los datos faltantes a la categoría 'other', ya que es la opción más adecuada para los valores ausentes en esta columna. Esto permitirá mantener la integridad de los datos y asegurará que todas las filas tengan una clasificación válida en términos de tipo de vehículo.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna 'gearbox'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['gearbox'].value_counts())\n",
    "print('---------------------------------')\n",
    "print(df['gearbox'].isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al analizar la columna 'gearbox', se observa que existen dos categorías: 'manual' y 'automático'. Sin embargo, se encontraron 9,488 valores faltantes en esta columna.\n",
    "\n",
    "**Decisión sobre la columna 'gearbox':** Dado que la categoría 'manual' es la más frecuente en el dataset (240,794 filas) en comparación con la categoría 'automático' (60,865 filas), se ha decidido imputar los valores faltantes en la categoría 'manual'. Esta decisión se basa en la frecuencia y en el hecho de que 'manual' es la opción más común para la mayoría de los automóviles listados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['model'].value_counts())\n",
    "print('---------------------------------')\n",
    "print(df['model'].isna().sum())\n",
    "print('---------------------------------')\n",
    "print(df['model'].nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de analizar la columna 'model', se encontró que hay 248 valores únicos en esta columna. Esto podría aumentar la complejidad del modelo y potencialmente generar problemas de sobreajuste. Además, si se utiliza una técnica de codificación como la codificación one-hot, se generarían 248 columnas adicionales, lo que a su vez aumentaría el número de parámetros del modelo y podría afectar su capacidad de generalización.\n",
    "\n",
    "**Decisión sobre la columna 'model':** Con el objetivo de evitar problemas de sobreajuste y mejorar la capacidad del modelo para generalizar a nuevos datos, se ha decidido eliminar la columna 'model' del conjunto de datos. Esta acción reducirá la complejidad del modelo y permitirá un enfoque más sencillo en la predicción del valor de mercado de los automóviles."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna 'fuel_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['fuel_type'].value_counts())\n",
    "print('---------------------------------')\n",
    "print(df['fuel_type'].isna().sum())\n",
    "print('---------------------------------')\n",
    "print(df['fuel_type'].nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de analizar la columna 'fuel_type', se encontraron datos faltantes en esta columna. Además, se observó que hay 7 valores posibles en total para indicar el tipo de combustible utilizado por el automóvil.\n",
    "\n",
    "**Decisión sobre la columna 'fuel_type':** Para conservar la información disponible en los registros y evitar la eliminación de datos importantes, se ha decidido imputar los valores faltantes en la categoría 'other'. Esta opción permite agrupar los datos ausentes en una categoría general que representa otros tipos de combustible no especificados en la lista original."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna 'brand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['brand'].value_counts())\n",
    "print('---------------------------------')\n",
    "print(df['brand'].isna().sum())\n",
    "print('---------------------------------')\n",
    "print(df['brand'].nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de analizar la columna 'brand', se encontraron 40 marcas únicas dentro de las posibles respuestas, y no existen datos ausentes en ella. Es importante tener en cuenta que, al tener un gran número de valores únicos en una columna, puede aumentar la posibilidad de sobreajuste del modelo.\n",
    "\n",
    "Después de evaluar el impacto que tiene la columna 'brand' en el modelo y considerar opciones para reducir su dimensionalidad, se ha decidido eliminar la columna del dataset para evitar el sobreajuste del modelo. Aunque existe la codificación de hash (Hash Encoding) y la codificación de embeddings (Embedding Encoding) para convertir variables categóricas en numéricas, se considera que eliminar la columna 'brand' es la mejor opción en este caso.\n",
    "\n",
    "Al eliminar la columna 'brand', se reduce la cantidad de características que se utilizan en el modelo, lo que puede mejorar la capacidad de generalización del modelo a datos nuevos e independientes. También se simplifica la tarea de encoding y se reduce el riesgo de sobreajuste."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna 'not_repaired'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['not_repaired'].value_counts())\n",
    "print('---------------------------------')\n",
    "print(df['not_repaired'].isna().sum())\n",
    "print('---------------------------------')\n",
    "print(df['not_repaired'].nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En relación con la columna 'not_repaired', se encontraron dos posibles respuestas: \"sí\" y \"no\". Sin embargo, se identificaron 47,733 valores ausentes en esta columna.\n",
    "\n",
    "**Decisión sobre la columna 'not_repaired':** Para imputar los datos faltantes, se ha decidido asignar el valor \"no\" a los registros faltantes. Esta decisión se basa en la hipótesis de que los registros sin información disponible probablemente no hayan sido reparados, ya que no hay indicación de reparación en los datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En resumen sobres las columnas categóricas:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después del análisis de las columnas categóricas, se han tomado las siguientes decisiones para cada una de ellas:\n",
    "\n",
    "**Decisión sobre la columna *'vehicle_type*:** Se ha decidido colocar los datos ausentes dentro de la categoría 'other', ya que es la opción más adecuada para este tipo de datos faltantes.\n",
    "\n",
    "**Decisión sobre la columna *'gearbox*:** Los datos ausentes se imputarán en la categoría de 'manual', ya que es el valor más frecuente en el conjunto de datos (240,794 filas versus 60,865 de automáticos).\n",
    "\n",
    "**Decisión sobre la columna *'model*:** Se eliminará esta columna del conjunto de datos para evitar problemas de sobreajuste y mejorar la capacidad del modelo para generalizar a nuevos datos.\n",
    "\n",
    "**Decisión sobre la columna *'fuel_type*:** Los datos ausentes se imputarán dentro de la categoría 'other'.\n",
    "\n",
    "**Decisión sobre la columna *'brand*:** Se ha decidido eliminar la columna para reducir la cantidad de características en el modelo.\n",
    "\n",
    "**Decisión sobre la columna *'not_repaired*:** Se ha decidido asignar el valor 'no' a los registros faltantes, ya que es la categoría más probable para los vehículos sin información de reparaciones.\n",
    "\n",
    "Estas decisiones se aplicarán a continuación."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajo de eliminación de filas y/o columnas categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se procede a realizar la eliminación de los datos correspondiente a filas y/o columnas categóricas.\n",
    "\n",
    "# En 'vehicle_type' los valores ausentes se imputarán con el valor 'other'.\n",
    "df['vehicle_type'].fillna(value='other', axis=0, inplace=True)\n",
    "\n",
    "# En 'gearbox' los valores ausentes se imputarán con el valor 'manual'.\n",
    "df['gearbox'].fillna(value='manual', axis=0, inplace=True)\n",
    "\n",
    "# En 'fuel_type' los valores ausentes se imputarán con el valor 'other'.\n",
    "df['fuel_type'].fillna(value='other', axis=0, inplace=True)\n",
    "\n",
    "# En 'not_repaired' los valores ausentes se imputarán con el valor 'no'.\n",
    "df['not_repaired'].fillna(value='no', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por último, la columna 'model' y 'brand' se eliminarán del dataframe.\n",
    "\n",
    "df = df.drop(['model'], axis=1)\n",
    "df = df.drop(['brand'], axis=1)\n",
    "\n",
    "# Y también la columna 'is_zero' que se creó para el análisis de la columna 'registration_month'.\n",
    "\n",
    "df = df.drop(['is_zero'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Así se encuentra el dataset después de la limpieza de datos.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realizará una copia del dataset para cualquier eventualidad.\n",
    "\n",
    "df_clean = df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos con OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "df_enc = df_clean.copy()\n",
    "df_enc[['vehicle_type', 'gearbox', 'fuel_type', 'not_repaired']] = enc.fit_transform(df_clean[['vehicle_type', 'gearbox', 'fuel_type', 'not_repaired']])\n",
    "\n",
    "# Se crean las variables dummies para las columnas 'vehicle_type', 'gearbox', 'fuel_type', 'not_repaired'.\n",
    "df_ohe = pd.get_dummies(df_clean, columns=['vehicle_type', 'gearbox', 'fuel_type', 'not_repaired'], drop_first=True)\n",
    "\n",
    "df_ohe.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de features y target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se separan los datos para la validación del modelo.\n",
    "rest_enc, valid = train_test_split(df_enc, test_size=0.2, random_state=rs)\n",
    "\n",
    "# También para el entrenamiento y prueba del modelo.\n",
    "train, test = train_test_split(rest_enc, test_size=0.25, random_state=rs)\n",
    "\n",
    "# Se crean las variables objetivo y predictores para el entrenamiento, prueba y validación del modelo.\n",
    "features_train_enc = train.drop(['price'], axis=1)\n",
    "target_train_enc = train['price']\n",
    "\n",
    "features_test_enc = test.drop(['price'], axis=1)\n",
    "target_test_enc = test['price']\n",
    "\n",
    "features_valid_enc = valid.drop(['price'], axis=1)\n",
    "target_valid_enc = valid['price'] \n",
    "\n",
    "# Y para el entrenamiento de la validación.\n",
    "features_rest_enc = rest_enc.drop(['price'], axis=1)\n",
    "target_rest_enc = rest_enc['price']\n",
    "\n",
    "# Se comprueban los tamaño de los conjuntos de datos.\n",
    "print(features_train_enc.shape)\n",
    "print(target_train_enc.shape)\n",
    "print(features_test_enc.shape)\n",
    "print(target_test_enc.shape)\n",
    "print(features_valid_enc.shape)\n",
    "print(target_valid_enc.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos con OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se separan los datos para la validación del modelo.\n",
    "rest_ohe, valid = train_test_split(df_ohe, test_size=0.2, random_state=rs)\n",
    "\n",
    "# También para el entrenamiento y prueba del modelo.\n",
    "train, test = train_test_split(rest_ohe, test_size=0.25, random_state=rs)\n",
    "\n",
    "# Se crean las variables objetivo y predictores para el entrenamiento, prueba y validación del modelo.\n",
    "features_train_ohe = train.drop(['price'], axis=1)\n",
    "target_train_ohe = train['price']\n",
    "\n",
    "features_test_ohe = test.drop(['price'], axis=1)\n",
    "target_test_ohe = test['price']\n",
    "\n",
    "features_valid_ohe = valid.drop(['price'], axis=1)\n",
    "target_valid_ohe = valid['price']\n",
    "\n",
    "# Y para el entrenamiento de la validación.\n",
    "features_rest_ohe = rest_ohe.drop(['price'], axis=1)\n",
    "target_rest_ohe = rest_ohe['price']\n",
    "\n",
    "# Se comprueban los tamaño de los conjuntos de datos.\n",
    "print(features_train_ohe.shape)\n",
    "print(target_train_ohe.shape)\n",
    "print(features_test_ohe.shape)\n",
    "print(target_test_ohe.shape)\n",
    "print(features_valid_ohe.shape)\n",
    "print(target_valid_ohe.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos sin codificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se separan los datos para la validación del modelo con datos sin codificar.\n",
    "rest, valid = train_test_split(df, test_size=0.2, random_state=rs)\n",
    "\n",
    "# También para el entrenamiento y prueba del modelo.\n",
    "train, test = train_test_split(rest, test_size=0.25, random_state=rs)\n",
    "\n",
    "# Se crean las variables objetivo y predictores para el entrenamiento, prueba y validación del modelo.\n",
    "features_train = train.drop(['price'], axis=1)\n",
    "target_train = train['price']\n",
    "\n",
    "features_test = test.drop(['price'], axis=1)\n",
    "target_test = test['price']\n",
    "\n",
    "features_valid = valid.drop(['price'], axis=1)\n",
    "target_valid = valid['price']\n",
    "\n",
    "# Y para el entrenamiento de la validación.\n",
    "features_rest = rest.drop(['price'], axis=1)\n",
    "target_rest = rest['price']\n",
    "\n",
    "# Se comprueban los tamaño de los conjuntos de datos.\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de cordura con regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "\n",
    "# Se entrena el modelo y se mide el tiempo\n",
    "start_time = time.time()\n",
    "reg.fit(features_train_ohe, target_train_ohe)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Se hacen predicciones y se mide el tiempo\n",
    "start_time = time.time()\n",
    "reg_pred_ohe = reg.predict(features_valid_ohe)\n",
    "pred_time = time.time() - start_time\n",
    "\n",
    "# Se calcula el RECM\n",
    "rmse = mean_squared_error(target_valid_ohe, reg_pred_ohe, squared=False)\n",
    "\n",
    "# Se imprimien los resultados\n",
    "print(f'Tiempo de entrenamiento: {train_time:.2f} segundos')\n",
    "print(f'Tiempo de predicción: {pred_time:.2f} segundos')\n",
    "print(f'RECM: {rmse:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bosque aleatorio con ajuste de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se configuran parámetros\n",
    "best_score = float('inf')\n",
    "n = 1\n",
    "\n",
    "# Se entrena y evalúa el modelo para diferentes parámetros\n",
    "for roots in range(3, 8):\n",
    "    for leafs in range(3, 8):\n",
    "        print(f'Ronda {n}')\n",
    "        \n",
    "        # Se crea el modelo y se miden tiempos de entrenamiento\n",
    "        forest = RandomForestRegressor(random_state=rs, max_depth=roots, min_samples_leaf=leafs)\n",
    "        start_time = time.time()\n",
    "        forest.fit(features_train_enc, target_train_enc)\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Se hacen predicciones y se mide el tiempo de predicción\n",
    "        start_time = time.time()\n",
    "        f_pred = forest.predict(features_valid_enc)\n",
    "        pred_time = time.time() - start_time\n",
    "        \n",
    "        # Se calcula el RECM\n",
    "        rmse = mean_squared_error(target_valid_enc, f_pred, squared=False)\n",
    "        print(f'Tiempo de entrenamiento: {train_time:.2f} segundos')\n",
    "        print(f'Tiempo de predicción: {pred_time:.2f} segundos')\n",
    "        print(f'RECM: {rmse:.2f}')\n",
    "        print()\n",
    "        \n",
    "        # Y se guarda el modelo con el mejor RECM\n",
    "        if rmse < best_score:\n",
    "            best_score = rmse\n",
    "            best_root = roots\n",
    "            best_leaf = leafs\n",
    "            best_pred = f_pred\n",
    "            best_n = n\n",
    "            \n",
    "        n += 1\n",
    "\n",
    "# Entrenar modelo con los mejores parámetros\n",
    "best_forest = RandomForestRegressor(random_state=rs, max_depth=best_root, min_samples_leaf=best_leaf)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f'Mejor ronda: {best_n}')\n",
    "print(f'Mejor RECM: {best_score:.2f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa, la mejor ronda fue la 24 con un RECM de 2193.81 que mejor el RECM de la prueba de cordura que fue de 2854.45."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear modelo y medir tiempo de entrenamiento\n",
    "cat = CatBoostRegressor(iterations=200, cat_features=['vehicle_type', 'fuel_type', 'not_repaired', 'gearbox'])\n",
    "start_time = time.time()\n",
    "cat.fit(features_train, target_train, eval_set=(features_valid, target_valid))\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Hacer predicciones y medir tiempo de predicción\n",
    "start_time = time.time()\n",
    "cat_pred = cat.predict(features_valid)\n",
    "pred_time = time.time() - start_time\n",
    "\n",
    "# Calcular RECM\n",
    "rmse = mean_squared_error(target_valid, cat_pred, squared=False)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f'Tiempo de entrenamiento: {train_time:.2f} segundos')\n",
    "print(f'Tiempo de predicción: {pred_time:.2f} segundos')\n",
    "print(f'RECM: {rmse:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el CatBoost se mejoró la RECM y ahora se ubica en 1936.89 (versus 2193.81 del bosque aleatorio y de 2854.45 de la regresión lineal)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM con ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con esta función se convierten columnas a tipo 'category'\n",
    "def convert_columns_to_category(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].astype('category')\n",
    "    return df\n",
    "\n",
    "# Luego se convierten columnas categóricas para cada conjunto de datos\n",
    "categorical_columns = ['vehicle_type', 'fuel_type', 'not_repaired', 'gearbox']\n",
    "features_train = convert_columns_to_category(features_train, categorical_columns)\n",
    "features_valid = convert_columns_to_category(features_valid, categorical_columns)\n",
    "features_test = convert_columns_to_category(features_test, categorical_columns)\n",
    "features_rest = convert_columns_to_category(features_rest, categorical_columns)\n",
    "\n",
    "# Se crea el modelo y se miden el tiempo de entrenamiento\n",
    "lgbm = lgb.LGBMRegressor(random_state=rs, learning_rate=0.05, n_estimators=500,\n",
    "                         max_depth=5, num_leaves=31, min_child_samples=20,\n",
    "                         subsample=0.8, colsample_bytree=0.8)\n",
    "\n",
    "start_time = time.time()\n",
    "lgbm.fit(features_train, target_train, eval_metric='RMSE',\n",
    "         categorical_feature=categorical_columns, eval_set=(features_valid, target_valid))\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Se hacen las predicciones y se mide el tiempo de predicción\n",
    "start_time = time.time()\n",
    "lgbm_pred = lgbm.predict(features_valid)\n",
    "pred_time = time.time() - start_time\n",
    "\n",
    "# Se calcula el RECM\n",
    "rmse = mean_squared_error(target_valid, lgbm_pred, squared=False)\n",
    "\n",
    "# Se imprimen los resultados\n",
    "print(f'Tiempo de entrenamiento: {train_time:.2f} segundos')\n",
    "print(f'Tiempo de predicción: {pred_time:.2f} segundos')\n",
    "print(f'RECM: {rmse:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis del modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tomar una decisión sobre qué modelo es el mejor, debemos considerar tanto el rendimiento como el tiempo de computación.\n",
    "\n",
    "Veamos los números:\n",
    "\n",
    "**Bosque aleatorio:** El tiempo de entrenamiento es bastante largo (22.82 segundos) y el RECM es el segundo más alto (2193.81).\n",
    "\n",
    "**Regresión lineal:** El tiempo de entrenamiento y predicción es el más bajo, pero también es el que tiene el RECM más alto (2854.45), lo que significa que es el menos preciso.\n",
    "\n",
    "**CatBoost:** Este tiene el RECM más bajo de todos los modelos (1936.89), lo que indica que es el más preciso. Aunque su tiempo de entrenamiento es alto (22.39 segundos), es ligeramente menor que el del Bosque Aleatorio. Además, su tiempo de predicción es significativamente más rápido que el de los otros modelos (0.10 segundos).\n",
    "\n",
    "**LightGBM:** Aunque tiene un RECM ligeramente más alto que el CatBoost (1944.44), su tiempo de entrenamiento es significativamente más corto (2.81 segundos), lo que puede ser una ventaja dependiendo de las circunstancias.\n",
    "\n",
    "Si consideramos solo el rendimiento, el modelo CatBoost sería el mejor, ya que tiene el RECM más bajo, lo que indica que es el más preciso.\n",
    "\n",
    "Sin embargo, si también consideramos el tiempo de entrenamiento y predicción, LightGBM podría ser una opción mejor. Aunque su RECM es ligeramente más alto que el de CatBoost, su tiempo de entrenamiento es mucho más corto, lo que podría ser una ventaja si necesitamos entrenar el modelo con frecuencia o si trabajamos con un conjunto de datos muy grande.\n",
    "\n",
    "Para este proyecto se eligirá como mejor modelo al **LightGBM** porque tiene mejor equilibrio entre precisión y eficiencia computacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el modelo\n",
    "lgbm = lgb.LGBMRegressor(random_state=rs)\n",
    "\n",
    "# Se mide tiempo de entrenamiento\n",
    "start_time = time.time()\n",
    "lgbm.fit(features_rest, target_rest, eval_metric = 'RMSE', \n",
    "         categorical_feature=['vehicle_type', 'fuel_type', 'not_repaired', 'gearbox'], \n",
    "         eval_set=(features_test, target_test))\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "print(f'Tiempo de entrenamiento: {train_time:.2f} segundos')\n",
    "\n",
    "# Se midel el tiempo de predicción\n",
    "start_time = time.time()\n",
    "lgbm_pred = lgbm.predict(features_test)\n",
    "pred_time = time.time() - start_time\n",
    "\n",
    "print(f'Tiempo de predicción: {pred_time:.2f} segundos')\n",
    "\n",
    "# Se calcula e imprime el RECM\n",
    "rmse = mean_squared_error(target_test, lgbm_pred, squared=False)\n",
    "print(f'RECM: {rmse:.2f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Iteración | RMSE    |\n",
    "|----------:|--------:|\n",
    "| 1         | 4241.63 |\n",
    "| 2         | 3957.93 |\n",
    "| 3         | 3710.92 |\n",
    "| 4         | 3489.42 |\n",
    "| 5         | 3298.87 |\n",
    "| 6         | 3135.63 |\n",
    "| 7         | 2990.74 |\n",
    "| 8         | 2865.51 |\n",
    "| 9         | 2757.10 |\n",
    "| 10        | 2664.85 |\n",
    "| 11        | 2581.47 |\n",
    "| 12        | 2508.86 |\n",
    "| 13        | 2447.89 |\n",
    "| 14        | 2394.33 |\n",
    "| 15        | 2348.26 |\n",
    "| 16        | 2308.58 |\n",
    "| 17        | 2273.39 |\n",
    "| 18        | 2243.22 |\n",
    "| 19        | 2217.47 |\n",
    "| 20        | 2194.01 |\n",
    "| 21        | 2173.84 |\n",
    "| 22        | 2156.77 |\n",
    "| 23        | 2139.97 |\n",
    "| 24        | 2125.84 |\n",
    "| 25        | 2111.86 |\n",
    "| 100       | 1924.40 |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, el tiempo de entrenamiento con los datos de validación pasó de 2.81 segundos a 1.05 segundos, mientras que el tiempo de predicción disminuyó de 0.32 segundos a 0.07 segundos. Además, el RECM se redujo de 1944.44 a 1924.40. Estos resultados indican que el modelo LightGBM logró mejorar tanto los tiempos de ejecución como la precisión de las predicciones.\n",
    "\n",
    "En conclusión, el modelo LightGBM resultó ser una buena opción para mejorar los tiempos de ejecución y predicción en comparación con los otros modelos evaluados.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
